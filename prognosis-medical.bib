@article{yao2020,
title = {Whole slide images based cancer survival prediction using attention guided deep multiple instance learning networks},
journal = {Medical Image Analysis},
volume = {65},
pages = {101789},
year = {2020},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2020.101789},
url = {https://www.sciencedirect.com/science/article/pii/S1361841520301535},
author = {Jiawen Yao and Xinliang Zhu and Jitendra Jonnagaddala and Nicholas Hawkins and Junzhou Huang},
keywords = {Survival prediction, Multiple instance learning, Deep learning, Whole slide images},
abstract = {Traditional image-based survival prediction models rely on discriminative patch labeling which make those methods not scalable to extend to large datasets. Recent studies have shown Multiple Instance Learning (MIL) framework is useful for histopathological images when no annotations are available in classification task. Different to the current image-based survival models that limit to key patches or clusters derived from Whole Slide Images (WSIs), we propose Deep Attention Multiple Instance Survival Learning (DeepAttnMISL) by introducing both siamese MI-FCN and attention-based MIL pooling to efficiently learn imaging features from the WSI and then aggregate WSI-level information to patient-level. Attention-based aggregation is more flexible and adaptive than aggregation techniques in recent survival models. We evaluated our methods on two large cancer whole slide images datasets and our results suggest that the proposed approach is more effective and suitable for large datasets and has better interpretability in locating important patterns and features that contribute to accurate cancer survival predictions. The proposed framework can also be used to assess individual patient’s risk and thus assisting in delivering personalized medicine.}
}
@article{
mobadersany2018,
author = {Pooya Mobadersany  and Safoora Yousefi  and Mohamed Amgad  and David A. Gutman  and Jill S. Barnholtz-Sloan  and José E. Velázquez Vega  and Daniel J. Brat  and Lee A. D. Cooper },
title = {Predicting cancer outcomes from histology and genomics using convolutional networks},
journal = {Proceedings of the National Academy of Sciences},
volume = {115},
number = {13},
pages = {E2970-E2979},
year = {2018},
doi = {10.1073/pnas.1717139115},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1717139115},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1717139115},
abstract = {Cancer histology reflects underlying molecular processes and disease progression and contains rich phenotypic information that is predictive of patient outcomes. In this study, we show a computational approach for learning patient outcomes from digital pathology images using deep learning to combine the power of adaptive machine learning algorithms with traditional survival models. We illustrate how these survival convolutional neural networks (SCNNs) can integrate information from both histology images and genomic biomarkers into a single unified framework to predict time-to-event outcomes and show prediction accuracy that surpasses the current clinical paradigm for predicting the overall survival of patients diagnosed with glioma. We use statistical sampling techniques to address challenges in learning survival from histology images, including tumor heterogeneity and the need for large training cohorts. We also provide insights into the prediction mechanisms of SCNNs, using heat map visualization to show that SCNNs recognize important structures, like microvascular proliferation, that are related to prognosis and that are used by pathologists in grading. These results highlight the emerging role of deep learning in precision medicine and suggest an expanding utility for computational analysis of histology in the future practice of pathology.}}
